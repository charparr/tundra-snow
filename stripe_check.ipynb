{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cparr/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# Data wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from collections import defaultdict\n",
    "\n",
    "# Plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# View a DataFrame in browser\n",
    "import webbrowser\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# Analysis Libraries\n",
    "import scipy\n",
    "import cv2\n",
    "from scipy.spatial import *\n",
    "from scipy.ndimage import *\n",
    "from skimage.transform import *\n",
    "from skimage.morphology import *\n",
    "from skimage.util import *\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_mse as mse\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "from skimage.transform import AffineTransform\n",
    "from skimage.transform import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Similarity Test Functions ###\n",
    "\n",
    "def procrustes_analysis(data):\n",
    "    for d in data:\n",
    "        mtx1, mtx2, disparity = procrustes(data[0], d)\n",
    "        # disparity is the sum of the square errors\n",
    "        # mtx2 is the optimal matrix transformation\n",
    "        disp_vals.append(disparity.round(3))\n",
    "        \n",
    "def peak_snr(data, x):\n",
    "    for d in data:\n",
    "        psnr_vals.append( psnr ( data[0], d, dynamic_range = x ).round(3))\n",
    "\n",
    "def make_quadrants(data):\n",
    "    \n",
    "    q = data[0].shape[0] / 2\n",
    "    for d in data:\n",
    "        tl, tr, ll, lr = d[:q, :q], d[q:, :q], d[:q, q:], d[q:, q:]\n",
    "        top_lefts.append(tl)\n",
    "        top_rights.append(tr)\n",
    "        low_lefts.append(ll)\n",
    "        low_rights.append(tr)\n",
    "        \n",
    "def structural_sim(data):\n",
    "    \n",
    "    for d in data:\n",
    "        ssim_vals.append( ssim ( data[0], d ).round( 2 ))\n",
    "        \n",
    "        ssim_maps.append( ssim ( data[0], d, full  = True )[1] )\n",
    "        \n",
    "def reg_mse(data):\n",
    "    for d in data:\n",
    "        mse_vals.append(( mse ( data[0], d )).round(2))\n",
    "        mse_maps.append((data[0] - d) ** 2)\n",
    "\n",
    "        \n",
    "def imse( data ):\n",
    "    \n",
    "    for d in data:\n",
    "\n",
    "        unique_vals_and_counts = np.round( np.unique( data[0], return_counts = True ), 1 )\n",
    "        vals = np.array( unique_vals_and_counts[0], dtype = 'float32' )\n",
    "        counts = np.array( unique_vals_and_counts[1], dtype = 'float32' )\n",
    "        num_pixels = data[0].size\n",
    "\n",
    "        shannons = np.round( np.divide( counts, num_pixels ), 6 )\n",
    "        info_vals = np.round( np.log(1/shannons), 2)\n",
    "\n",
    "        unique_info_vals = zip(vals,info_vals)\n",
    "        trans_dct = {}\n",
    "\n",
    "        for v in unique_info_vals:\n",
    "            trans_dct[v[0]] = v[1]\n",
    "\n",
    "        infomap = np.copy( data[0] )\n",
    "        for k, v in trans_dct.iteritems(): infomap[data[0] == k] = v\n",
    "\n",
    "        imse_map = (( infomap * data[0] ) - ( infomap * d )) ** 2\n",
    "        imse_maps.append(imse_map)\n",
    "        \n",
    "        err = np.sum( imse_map )\n",
    "        err /= float(data[0].shape[0] * data[0].shape[1])\n",
    "\n",
    "        imse_vals.append( np.round(err, 2 ))\n",
    "    \n",
    "        \n",
    "def np_hist_to_cv(np_histogram_output):\n",
    "    counts, bin_edges = np_histogram_output\n",
    "    return counts.ravel().astype('float32')\n",
    "\n",
    "### Plotting Functions ###\n",
    "\n",
    "# Function to display DataFrame in new browser tab.\n",
    "\n",
    "def df_window(df):\n",
    "    with NamedTemporaryFile(delete=False, suffix='.html') as f:\n",
    "        df.to_html(f)\n",
    "    webbrowser.open(f.name)\n",
    "\n",
    "# Plot binary patterns and distortions\n",
    "\n",
    "def plot_binary(names, data):\n",
    "\n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    for p, dat, ax in zip( names, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'gray', interpolation = 'nearest', vmin=0, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p,fontsize = 10, color = 'white')\n",
    "    \n",
    "    # if # subplots is strange\n",
    "    fig.delaxes(axes[-1,-1])\n",
    "    fig.delaxes(axes[-1,-2])\n",
    "    fig.delaxes(axes[-1,-3])\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ([0,1]) )\n",
    "    cax.tick_params(labelsize = 10, colors = 'white')\n",
    "\n",
    "# Plot continuous patterns and distortions\n",
    "\n",
    "def plot_continuous(names, data):\n",
    "    \n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    for p, dat, ax in zip( names, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'viridis', interpolation = 'nearest', vmin=-1, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p,fontsize = 10, color = 'white')\n",
    "    \n",
    "    # if # subplots is strange\n",
    "    \n",
    "    fig.delaxes(axes[-1,-1])\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ( [-1,0,1] ) )\n",
    "    cax.tick_params(labelsize = 10, colors = 'white')\n",
    "    \n",
    "def plot_snow(names, data):\n",
    "    \n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    fig.suptitle('Fidelity Tests of Snow Depth Patterns [m]', color = 'white')\n",
    "    for p, dat, ax in zip( names, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'viridis', interpolation = 'nearest', vmin = 0, vmax = 2)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p,fontsize = 8, color = 'white')\n",
    "    \n",
    "    # if # subplots is prime\n",
    "    \n",
    "    fig.delaxes(axes[-1,-1])\n",
    "    fig.delaxes(axes[-1,-2])\n",
    "    fig.delaxes(axes[-1,-3])\n",
    "\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ( [0,1,2] ) )\n",
    "    cax.tick_params(labelsize = 8, colors = 'white')\n",
    "    \n",
    "    \n",
    "def plot_tests(names, test_vals, test_name, data, rows, cols, cmin, cmax):\n",
    "    \n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    for p, v, dat, ax in zip( names, test_vals, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'viridis', interpolation = 'nearest', vmin = cmin, vmax = cmax)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p + \" \" + test_name + str(v), fontsize = 8, color = 'white' )\n",
    "    \n",
    "    # if # subplots is strange\n",
    "    if len(names) != rows*cols:\n",
    "        diff = -1*( rows*cols - len(names))\n",
    "        i = -1\n",
    "        while i >= diff:\n",
    "            fig.delaxes(axes[-1,i])\n",
    "            i = i-1\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ( [cmin, cmax] ) )\n",
    "    cax.tick_params(labelsize = 8, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Set of Reference Patterns\n",
    "\n",
    "# Horizontal Stripes alternating 4 white (1) and 4 black (0)\n",
    "stripes = np.zeros(( 32, 32 ))\n",
    "j = 0\n",
    "k = 4\n",
    "\n",
    "while k < 33:\n",
    "    stripes[j:k] = 1\n",
    "    j = j + 8\n",
    "    k = j + 4\n",
    "\n",
    "# from negative pi to pi\n",
    "pi_cycles = np.linspace( -np.pi, np.pi, 512 )\n",
    "# vertically stack two of the above\n",
    "pi_cycles = np.append( pi_cycles, pi_cycles )\n",
    "pi_cycles = pi_cycles.reshape( 32, 32 )\n",
    "\n",
    "# Sine Wave\n",
    "sine = np.sin( pi_cycles )\n",
    "\n",
    "# Cosine\n",
    "cosine = np.cos( pi_cycles )\n",
    "\n",
    "# Gaussian Noise\n",
    "mu = 0.5\n",
    "sigma = 0.15\n",
    "gauss = np.random.normal( mu, sigma, ( 32,32 ))\n",
    "\n",
    "#Snow\n",
    "\n",
    "src1 = rasterio.open( '/home/cparr/Snow_Patterns/snow_data/happy_valley/raster/snow_on/hv_snow_watertrack_square2012.tif' )\n",
    "snow_test = src1.read(1)\n",
    "snow_test = snow_test.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Warping a reference pattern of binary data.\n",
    "# '''\n",
    "# binwarp_data = []\n",
    "\n",
    "# # Initialize lists for metrics.\n",
    "\n",
    "# mse_vals = []\n",
    "# ssim_vals = []\n",
    "# psnr_vals = []\n",
    "\n",
    "# top_lefts = []\n",
    "# top_rights = []\n",
    "# low_lefts = []\n",
    "# low_rights = []\n",
    "\n",
    "# imse_vals = []\n",
    "# imse_maps = []\n",
    "\n",
    "\n",
    "\n",
    "# def warp_binary(pattern):\n",
    "    \n",
    "#     binwarp_data.append(pattern)\n",
    "    \n",
    "#     rows, cols = pattern.shape\n",
    "    \n",
    "#     # half phase shift for stripes\n",
    "#     half_phase = np.zeros((32, 32))\n",
    "\n",
    "#     j = 2\n",
    "#     k = 6\n",
    "\n",
    "#     while k < 33:\n",
    "#         half_phase[j:k] = 1\n",
    "#         j = j + 8\n",
    "#         k = j + 4\n",
    "\n",
    "#     binwarp_data.append(half_phase)\n",
    "    \n",
    "#     # 90 degree rotation\n",
    "#     rotate90 = np.rot90(pattern)\n",
    "#     binwarp_data.append(rotate90)\n",
    "    \n",
    "#     #45 degree rotation\n",
    "#     oblique = rotate(pattern, 45)\n",
    "#     binwarp_data.append(oblique)\n",
    "    \n",
    "#     # morphological dilation and erosion\n",
    "#     morph_dilation = dilation(pattern)\n",
    "#     morph_erosion = erosion(pattern)\n",
    "#     binwarp_data.append(morph_dilation)\n",
    "#     binwarp_data.append(morph_erosion)\n",
    "    \n",
    "#     # flip up and down, basically a full phase shift or reflection\n",
    "#     inverse = np.flipud(pattern)\n",
    "#     binwarp_data.append(inverse)\n",
    "    \n",
    "#     # a shift or translation\n",
    "#     shift_M = np.float32([[1,0,1],[0,1,0]])\n",
    "#     shifted = cv2.warpAffine(pattern,shift_M,(cols,rows))\n",
    "#     binwarp_data.append(shifted)\n",
    "    \n",
    "#     # randomly shuffle rows of array, create a random frequency\n",
    "#     permutation = np.random.permutation(pattern)\n",
    "#     binwarp_data.append(permutation)\n",
    "    \n",
    "    \n",
    "#     # Random Affine Transformation\n",
    "#     c = np.random.random_sample(( 6, ))\n",
    "#     m = np.append( c, ( 0,0,1 ) )\n",
    "#     m = m.reshape( 3,3 )\n",
    "#     aff_t = AffineTransform( matrix = m )\n",
    "#     random_aff_warp = warp( pattern, aff_t )\n",
    "#     binwarp_data.append( random_aff_warp )\n",
    "    \n",
    "#     # gauss\n",
    "#     binwarp_data.append(gauss)\n",
    "    \n",
    "#     # random binary\n",
    "#     random_bin = np.random.randint(2, size=1024)\n",
    "#     random_bin = random_bin.reshape(32,32)\n",
    "#     random_bin = random_bin.astype('float64')\n",
    "#     binwarp_data.append(random_bin)\n",
    "    \n",
    "#     # Finger edges\n",
    "#     edge = np.zeros(( 32, 32 ))\n",
    "#     j = 0\n",
    "#     k = 4\n",
    "\n",
    "#     while k < 33:\n",
    "#         edge[j:k] = 1\n",
    "#         j = j + 8\n",
    "#         k = j + 4\n",
    "    \n",
    "#     edge[3][1::2] = 0\n",
    "#     edge[7][1::2] = 1\n",
    "#     edge[11][1::2] = 0\n",
    "#     edge[15][1::2] = 1\n",
    "#     edge[19][1::2] = 0\n",
    "#     edge[23][1::2] = 1\n",
    "#     edge[27][1::2] = 0\n",
    "#     edge[31][1::2] = 1\n",
    "#     binwarp_data.append(edge)\n",
    "\n",
    "# # Subplot Titles and Dictionary Keys\n",
    "# binwarp_names = ['Original', 'Half Phase Shift', 'Rotate 90','Rotate 45',\n",
    "#                  'Dilation', 'Erosion','Flip U/D', 'X Shift',\n",
    "#                  'Row Shuffle', 'Random Affine', 'Gauss', 'Random','Edges']\n",
    "\n",
    "# # Call It.\n",
    "# warp_binary(stripes)\n",
    "\n",
    "# # Call Metrics on list of test patterns\n",
    "# peak_snr( binwarp_data, 64 )\n",
    "# # PSNR requires the dynamic range, e.g. 8-bit data is 255\n",
    "# structural_sim( binwarp_data )\n",
    "# reg_mse( binwarp_data )\n",
    "# #procrustes_analysis( binwarp_data )\n",
    "# # this doesn't seem to work for binary..\n",
    "# disp_vals = np.arange(0,13)\n",
    "# make_quadrants( binwarp_data )\n",
    "\n",
    "# imse(binwarp_data)\n",
    "\n",
    "# # Match names and arrays\n",
    "# binary_zip = zip(binwarp_names,binwarp_data, mse_vals, ssim_vals, psnr_vals, disp_vals,\n",
    "#                  top_lefts, top_rights, low_lefts, low_rights, imse_vals, imse_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Warping a base pattern of continuous data.\n",
    "# Applying MSE, SSIM, PSNR, and Procrustes.\n",
    "# Zipping all of these values into a mega - list.\n",
    "# Afterward, create a dict and a DataFrame by iterating through mega - list.\n",
    "# '''\n",
    "\n",
    "# ctswarp_data = []\n",
    "\n",
    "# # Initialize lists for metrics.\n",
    "\n",
    "# mse_vals = []\n",
    "# ssim_vals = []\n",
    "# psnr_vals = []\n",
    "# disp_vals = []\n",
    "\n",
    "# top_lefts = []\n",
    "# top_rights = []\n",
    "# low_lefts = []\n",
    "# low_rights = []\n",
    "\n",
    "# imse_vals = []\n",
    "# imse_maps = []\n",
    "\n",
    "# # Create the test patterns.\n",
    "# def warp_continuous(pattern):\n",
    "    \n",
    "#     ctswarp_data.append(pattern)\n",
    "    \n",
    "#     rows, cols = pattern.shape\n",
    "\n",
    "#     # 90 degree rotation\n",
    "#     rotate90 = np.rot90(pattern)\n",
    "#     ctswarp_data.append(rotate90)\n",
    "    \n",
    "#     #45 degree rotation\n",
    "#     oblique = rotate(pattern, 45)\n",
    "#     ctswarp_data.append(oblique)\n",
    "    \n",
    "#     # morphological dilation and erosion\n",
    "#     morph_dilation = dilation(pattern)\n",
    "#     morph_erosion = erosion(pattern)\n",
    "#     ctswarp_data.append(morph_dilation)\n",
    "#     ctswarp_data.append(morph_erosion)\n",
    "    \n",
    "#     # flip up and down, basically a phase shift\n",
    "#     inverse = np.flipud(pattern)\n",
    "#     ctswarp_data.append(inverse)\n",
    "    \n",
    "#     # a shift or translation\n",
    "#     shift_M = np.float32([[1,0,1],[0,1,0]])\n",
    "#     shifted = cv2.warpAffine(pattern,shift_M,(cols,rows))\n",
    "#     ctswarp_data.append(shifted)\n",
    "    \n",
    "#     # randomly shuffle rows of array, create a random frequency\n",
    "#     permutation = np.random.permutation(pattern)\n",
    "#     ctswarp_data.append(permutation)\n",
    "    \n",
    "#     # sine warp\n",
    "#     # basically sine of sine...reduces the intensity \n",
    "#     sine_of  = np.sin(pattern)\n",
    "#     ctswarp_data.append(sine_of)\n",
    "    \n",
    "#     # cosine\n",
    "#     ctswarp_data.append(cosine)\n",
    "    \n",
    "#     # Random between -1 and 1\n",
    "#     random_abs1 = np.random.uniform(-1, 1, [32,32])\n",
    "#     ctswarp_data.append(random_abs1)\n",
    "    \n",
    "#     # Gaussian noise\n",
    "#     mu = 0\n",
    "#     sigma = 0.32\n",
    "#     gauss_abs1 = np.random.normal(mu, sigma, (32,32))\n",
    "#     ctswarp_data.append(gauss_abs1)\n",
    "    \n",
    "#     # Random Affine Transformation\n",
    "#     c = np.random.random_sample(( 6, ))\n",
    "#     m = np.append( c, ( 0,0,1 ) )\n",
    "#     m = m.reshape( 3,3 )\n",
    "#     aff_t = AffineTransform( matrix = m )\n",
    "#     random_aff_warp = warp( pattern, aff_t )\n",
    "#     ctswarp_data.append( random_aff_warp )\n",
    "    \n",
    "#     # Additive Gaussian Noise\n",
    "#     noise = random_noise( pattern, mode = 'gaussian' )\n",
    "#     ctswarp_data.append( noise )\n",
    "    \n",
    "#     # More Additive Gaussian Noise\n",
    "#     more_noise = random_noise(random_noise(random_noise(random_noise( noise, mode = 'gaussian' ))))\n",
    "#     ctswarp_data.append( more_noise )\n",
    "    \n",
    "# # Plot Titles and dictionary keys\n",
    "# ctswarp_names = ['Reference', 'Rotate 90', 'Rotate 45', 'Dilation',\n",
    "#                  'Erosion', 'Flip U/D', 'X Shift', 'Row Shuffle',\n",
    "#                  'Sine (Reference)', 'Cosine', 'Random', 'Gauss',\n",
    "#                  'Random Affine', 'Add Gaussian Noise','More Noise']\n",
    "\n",
    "# # Call It.\n",
    "# warp_continuous( sine )\n",
    "\n",
    "# # Call Metrics on list of test patterns\n",
    "# peak_snr( ctswarp_data, 64 )\n",
    "# # PSNR requires the dynamic range, e.g. 8-bit data is 255\n",
    "# structural_sim( ctswarp_data )\n",
    "# reg_mse( ctswarp_data )\n",
    "# procrustes_analysis( ctswarp_data )\n",
    "# make_quadrants( ctswarp_data )\n",
    "\n",
    "# imse(ctswarp_data)\n",
    "\n",
    "# # Zip names, data, metrics, quadrants into a mega list!\n",
    "# # Generally this is indavisable because it relies on indexing...in the next cell we will make a dictionary.\n",
    "# continuous_zip = zip(ctswarp_names,ctswarp_data, mse_vals, ssim_vals, psnr_vals, disp_vals,\n",
    "#                      top_lefts, top_rights, low_lefts, low_rights, imse_vals, imse_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Snow Data Test\n",
    "'''\n",
    "\n",
    "snow_data = []\n",
    "\n",
    "# Initialize lists for metrics.\n",
    "\n",
    "mse_vals = []\n",
    "ssim_vals = []\n",
    "psnr_vals = []\n",
    "disp_vals = []\n",
    "\n",
    "top_lefts = []\n",
    "top_rights = []\n",
    "low_lefts = []\n",
    "low_rights = []\n",
    "\n",
    "imse_vals = []\n",
    "imse_maps = []\n",
    "\n",
    "mse_maps = []\n",
    "ssim_maps = []\n",
    "mse_maps = []\n",
    "\n",
    "# Create the test snows.\n",
    "def warp_snow(snow):\n",
    "    \n",
    "    snow_data.append(snow)\n",
    "    \n",
    "    rows, cols = snow.shape\n",
    "    mu = snow.mean()\n",
    "    sigma = snow.std()\n",
    "\n",
    "    # 90 degree rotation\n",
    "    rotate90 = np.rot90(snow)\n",
    "    snow_data.append(rotate90)\n",
    "    \n",
    "    #45 degree rotation\n",
    "    oblique = rotate(snow, 45)\n",
    "    b = oblique == 0\n",
    "    oblique[b] = np.random.normal(mu, sigma, size=b.sum())\n",
    "    snow_data.append(oblique)\n",
    "    \n",
    "    # morphological dilation and erosion\n",
    "\n",
    "    selem = square(7)\n",
    "    morph_dilation = dilation(snow, selem)\n",
    "    morph_erosion = erosion(snow, selem)\n",
    "    snow_data.append(morph_dilation)\n",
    "    snow_data.append(morph_erosion)\n",
    "    \n",
    "    # flip up and down, basically a phase shift\n",
    "    inverse = np.flipud(snow)\n",
    "    snow_data.append(inverse)\n",
    "    \n",
    "    # a shift or translation\n",
    "    shift_M = np.float32([[1,0,1],[0,1,0]])\n",
    "    shifted = cv2.warpAffine(snow,shift_M,(cols,rows))\n",
    "    snow_data.append(shifted)\n",
    "    \n",
    "    # randomly shuffle rows of array, create a random frequency\n",
    "    permutation = np.random.permutation(snow)\n",
    "    snow_data.append(permutation)\n",
    "    \n",
    "    # Random between bounds\n",
    "    random_abs1 = np.random.uniform(snow.min(), snow.max(), [rows, cols])\n",
    "    snow_data.append(random_abs1)\n",
    "    \n",
    "    # Gaussian noise\n",
    "    mu = snow.mean()\n",
    "    sigma = snow.std()\n",
    "    gauss_abs1 = np.random.normal(mu, sigma, (rows, cols))\n",
    "    snow_data.append(gauss_abs1)\n",
    "    \n",
    "    # Random Affine Transformation\n",
    "    c = np.random.random_sample(( 6, ))\n",
    "    m = np.append( c, ( 0,0,1 ) )\n",
    "    m = m.reshape( 3,3 )\n",
    "    aff_t = AffineTransform( matrix = m )\n",
    "    random_aff_warp = warp( snow, aff_t )\n",
    "    b = random_aff_warp == 0\n",
    "    random_aff_warp[b] = np.random.normal(mu, sigma, size=b.sum())\n",
    "    snow_data.append(random_aff_warp)\n",
    "    \n",
    "    # Additive Gaussian Noise\n",
    "    noise = random_noise( snow, mode = 'gaussian' )\n",
    "    snow_data.append( noise )\n",
    "    \n",
    "    # More Additive Gaussian Noise\n",
    "    more_noise = random_noise(random_noise(random_noise(random_noise( noise, mode = 'gaussian' ))))\n",
    "    snow_data.append( more_noise )\n",
    "    \n",
    "# Plot Titles and dictionary keys\n",
    "snow_names = ['Reference', 'Rotate 90', 'Rotate 45', 'Dilation',\n",
    "                 'Erosion', 'Y - Reflection', 'X Shift', 'Row Shuffle', 'Random', 'Gauss',\n",
    "                 'Random Affine', 'Add Gaussian Noise','More Noise']\n",
    "\n",
    "# Call It.\n",
    "warp_snow( snow_test )\n",
    "\n",
    "# Call Metrics on list of test snows\n",
    "\n",
    "peak_snr( snow_data, 64 )\n",
    "# PSNR requires the dynamic range, e.g. 8-bit data is 255\n",
    "\n",
    "structural_sim( snow_data )\n",
    "reg_mse( snow_data )\n",
    "procrustes_analysis( snow_data )\n",
    "make_quadrants( snow_data )\n",
    "\n",
    "imse(snow_data)\n",
    "\n",
    "# Zip names, data, metrics, quadrants into a mega list!\n",
    "# Generally this is indavisable because it relies on indexing...in the next cell we will make a dictionary.\n",
    "snow_zip = zip(snow_names,snow_data, mse_vals, ssim_vals, psnr_vals, disp_vals,\n",
    "                     top_lefts, top_rights, low_lefts, low_rights, imse_vals, imse_maps, mse_maps, ssim_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To plot\n",
    "\n",
    "#plot_binary( binwarp_names, binwarp_data )\n",
    "#plot_continuous( ctswarp_names, ctswarp_data )\n",
    "#plot_snow( snow_names, snow_data )\n",
    "\n",
    "# names, test_vals, test_name, data, rows, cols, cmin, cmax\n",
    "plot_tests( snow_names, ssim_vals, \" SSIM: \", ssim_maps, 4, 4, 0, 1 )\n",
    "\n",
    "# To save the figure\n",
    "\n",
    "#plt.savefig( '/home/cparr/stripe_world.png', bbox_inches = 'tight', dpi = 300, facecolor = 'purple' )\n",
    "#plt.savefig('/home/cparr/pi_world.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "\n",
    "#plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_snow_metric_test.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "\n",
    "#plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_ssim_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "#plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_mse_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "#plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_imse_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "fig.suptitle('Fidelity Tests of Snow Depth Patterns [m]', color = 'white')\n",
    "for p, dat, ax in zip( snow_names, snow_data, axes.flat ):\n",
    "    \n",
    "    contours = measure.find_contours(dat, 0.8)\n",
    "\n",
    "    # The vmin and vmax arguments specify the color limits\n",
    "    im = ax.imshow(dat, cmap = 'gray', interpolation = 'nearest', vmin = 0, vmax = 2)\n",
    "    \n",
    "    for n, contour in enumerate(contours):\n",
    "        if contour.size >= 150:\n",
    "            ax.plot(contour[:, 1], contour[:, 0], linewidth=0.5)\n",
    "\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(p,fontsize = 8, color = 'white')\n",
    "    ax.axis('image')\n",
    "\n",
    "\n",
    "# if # subplots is prime\n",
    "\n",
    "fig.delaxes(axes[-1,-1])\n",
    "fig.delaxes(axes[-1,-2])\n",
    "fig.delaxes(axes[-1,-3])\n",
    "\n",
    "\n",
    "# Make an axis for the colorbar on the bottom\n",
    "\n",
    "cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "fig.colorbar( im, cax=cax, ticks = ( [0,1,2] ) )\n",
    "cax.tick_params(labelsize = 8, colors = 'white')\n",
    "\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_contour_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.10429801698214"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours = measure.find_contours(snow_test, 0.8)\n",
    "l = []\n",
    "for c in contours:\n",
    "    l.append(c.size)\n",
    "np.mean(l)+np.std(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a look up dictionary from all the patterns and their comparison scores.\n",
    "continuous_dict = defaultdict(dict)\n",
    "binary_dict = defaultdict(dict)\n",
    "snow_dict = defaultdict(dict)\n",
    "\n",
    "\n",
    "def to_dict_w_hists( data_dict, keys, data_zip ):\n",
    "\n",
    "    i = 0\n",
    "    while i < len(keys):\n",
    "\n",
    "        data_dict[keys[i]]['name'] = data_zip[i][0]\n",
    "\n",
    "        # data_dict[keys[i]]['array'] = data_zip[i][1]\n",
    "\n",
    "        data_dict[keys[i]]['arrays'] = {}\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['full'] = {}\n",
    "        data_dict[keys[i]]['arrays']['full']['array'] = data_zip[i][1]\n",
    "        data_dict[keys[i]]['arrays']['full']['numpy hist'] = np.histogram( data_zip[i][1] )\n",
    "        data_dict[keys[i]]['arrays']['full']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][1] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['top left'] = {}\n",
    "        data_dict[keys[i]]['arrays']['top left']['array'] = data_zip[i][6]\n",
    "        data_dict[keys[i]]['arrays']['top left']['numpy hist'] = np.histogram( data_zip[i][6] )\n",
    "        data_dict[keys[i]]['arrays']['top left']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][6] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['top right'] = {}\n",
    "        data_dict[keys[i]]['arrays']['top right']['array'] = data_zip[i][7]\n",
    "        data_dict[keys[i]]['arrays']['top right']['numpy hist'] = np.histogram( data_zip[i][7] )\n",
    "        data_dict[keys[i]]['arrays']['top right']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][7] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['low left'] = {}\n",
    "        data_dict[keys[i]]['arrays']['low left']['array'] = data_zip[i][8]\n",
    "        data_dict[keys[i]]['arrays']['low left']['numpy hist'] = np.histogram( data_zip[i][8] )\n",
    "        data_dict[keys[i]]['arrays']['low left']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][8] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['low right'] = {}\n",
    "        data_dict[keys[i]]['arrays']['low right']['array'] = data_zip[i][9]\n",
    "        data_dict[keys[i]]['arrays']['low right']['numpy hist'] = np.histogram( data_zip[i][9] )\n",
    "        data_dict[keys[i]]['arrays']['low right']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][9] ) )    \n",
    "\n",
    "        data_dict[keys[i]]['MSE'] = round(data_zip[i][2], 2)\n",
    "        data_dict[keys[i]]['SSIM'] = round(data_zip[i][3], 2)\n",
    "        data_dict[keys[i]]['Peak SNR'] = round(data_zip[i][4], 2)\n",
    "        data_dict[keys[i]]['Procrustres Disparity'] = round(data_zip[i][5], 2)\n",
    "        #\n",
    "        data_dict[keys[i]]['IMSE'] = round(data_zip[i][10], 2)\n",
    "        data_dict[keys[i]]['IMSE Map'] = data_zip[i][11]\n",
    "        \n",
    "\n",
    "        # Histogram Comparisons\n",
    "\n",
    "        # Bhattacharyya\n",
    "        data_dict[keys[i]]['Bhattacharyya Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)   \n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        # Chi Square\n",
    "        data_dict[keys[i]]['Chi Square Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        # Correlation\n",
    "        data_dict[keys[i]]['Correlation Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to_dict_w_hists( binary_dict, binwarp_names, binary_zip )\n",
    "#to_dict_w_hists( continuous_dict, ctswarp_names, continuous_zip )\n",
    "to_dict_w_hists( snow_dict, snow_names, snow_zip )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Continuous Scores DataFrame\n",
    "\n",
    "# cts_df = pd.DataFrame.from_dict(continuous_dict)\n",
    "# cts_df = cts_df.transpose()\n",
    "\n",
    "# continuous_scores = cts_df.copy()\n",
    "# continuous_scores = continuous_scores[['MSE','SSIM','Peak SNR','Procrustres Disparity', 'IMSE','name']]\n",
    "\n",
    "# continuous_scores['MSE Rank'] = np.round(continuous_scores['MSE'].rank(ascending=True))\n",
    "# continuous_scores['PSNR Rank'] = np.round(continuous_scores['Peak SNR'].rank(ascending=False))\n",
    "# continuous_scores['SSIM Rank'] = np.round(continuous_scores['SSIM'].rank(ascending=False))\n",
    "# continuous_scores['PD Rank'] = np.round(continuous_scores['Procrustres Disparity'].rank())\n",
    "# continuous_scores['IMSE Rank'] = np.round(continuous_scores['IMSE'].rank(ascending=True))\n",
    "\n",
    "\n",
    "# continuous_scores = continuous_scores.sort_values('SSIM Rank')\n",
    "\n",
    "# df_window(continuous_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Binary Scores DataFrame\n",
    "\n",
    "# bin_df = pd.DataFrame.from_dict(binary_dict)\n",
    "# bin_df = bin_df.transpose()\n",
    "\n",
    "# binary_scores = bin_df.copy()\n",
    "# binary_scores = binary_scores[['MSE','SSIM','Peak SNR','IMSE','name']]\n",
    "\n",
    "# binary_scores['MSE Rank'] = np.round(binary_scores['MSE'].rank(ascending=True))\n",
    "# binary_scores['PSNR Rank'] = np.round(binary_scores['Peak SNR'].rank(ascending=False))\n",
    "# binary_scores['SSIM Rank'] = binary_scores['SSIM'].rank(ascending=False)\n",
    "# binary_scores['IMSE Rank'] = np.round(binary_scores['IMSE'].rank(ascending=True))\n",
    "# binary_scores = binary_scores.sort_values('SSIM Rank')\n",
    "\n",
    "# df_window(binary_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Snow Scores DataFrame\n",
    "\n",
    "snow_df = pd.DataFrame.from_dict(snow_dict)\n",
    "snow_df = snow_df.transpose()\n",
    "\n",
    "snow_scores = snow_df.copy()\n",
    "snow_scores = snow_scores[['MSE','SSIM','Peak SNR','Procrustres Disparity', 'IMSE','name']]\n",
    "\n",
    "snow_scores = snow_scores.sort_values('SSIM', ascending = False)\n",
    "\n",
    "df_window(snow_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist_score_table(df):\n",
    "    \n",
    "    hist_scores = df.loc[:,['name', 'Bhattacharyya UL','Bhattacharyya UR','Bhattacharyya LL',\n",
    "    'Bhattacharyya LR', 'Bhattacharyya Full','Correlation UL','Correlation UR','Correlation LL',\n",
    "    'Correlation LR', 'Correlation Full','Chi Square UL','Chi Square UR','Chi Square LL',\n",
    "    'Chi Square LR', 'Chi Square Full']]\n",
    "\n",
    "    hist_scores['Mean Bhattacharyya'] = np.round(hist_scores[['Bhattacharyya UL','Bhattacharyya UR',\n",
    "                                                'Bhattacharyya LL', 'Bhattacharyya LR']].mean(axis = 1),2)\n",
    "\n",
    "    hist_scores['Mean Correlation'] = np.round(hist_scores[['Correlation UL','Correlation UR',\n",
    "                                                'Correlation LL', 'Correlation LR']].mean(axis = 1),2)\n",
    "\n",
    "    hist_scores['Mean Chi Square'] = np.round(hist_scores[['Chi Square UL','Chi Square UR',\n",
    "                                                'Chi Square LL', 'Chi Square LR']].mean(axis = 1),2)\n",
    "    \n",
    "    hist_scores = hist_scores[['Mean Bhattacharyya', 'Mean Chi Square','Mean Correlation']]\n",
    "    \n",
    "    \n",
    "    hist_scores = hist_scores.sort_values('Mean Bhattacharyya')\n",
    "    \n",
    "    \n",
    "    df_window(hist_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hist_score_table(cts_df)\n",
    "#hist_score_table(bin_df)\n",
    "hist_score_table(snow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.color_palette(\"spectral\", n_colors=15):\n",
    "    g = sns.pairplot(continuous_scores, x_vars = ['MSE Rank'],\n",
    "                     y_vars = ['PSNR Rank','SSIM Rank','PD Rank'], hue = 'name',\n",
    "                     plot_kws=dict(s=150, edgecolor=\"b\", linewidth=1))\n",
    "\n",
    "\n",
    "labels = continuous_scores['name'].tolist()\n",
    "\n",
    "g.set(xlim=(0, 16))\n",
    "g.fig.set_tight_layout('tight')\n",
    "#g.savefig('/home/cparr/cts_scores.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_strip_plot(df,metric):\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Make the PairGrid\n",
    "    g = sns.PairGrid(df.sort_values(metric, ascending=True),\n",
    "                     x_vars = df.columns[1::], y_vars=[\"name\"],\n",
    "                     size=10, aspect=.25)\n",
    "\n",
    "    # Draw a dot plot using the stripplot function\n",
    "    g.map(sns.stripplot, size=10, orient=\"h\",\n",
    "          palette=\"Reds_r\", edgecolor=\"gray\")\n",
    "\n",
    "    # Use the same x axis limits on all columns and add better labels\n",
    "    #g.set(xlim=(df[metric].min(), df[metric].max()), xlabel=\"Score\", ylabel=\"\")\n",
    "\n",
    "    # Use semantically meaningful titles for the columns\n",
    "    titles = df.columns[1::]\n",
    "\n",
    "    for ax, title in zip(g.axes.flat, titles):\n",
    "\n",
    "        # Set a different title for each axes\n",
    "        ax.set(title=title)\n",
    "\n",
    "        # Make the grid horizontal instead of vertical\n",
    "        ax.xaxis.grid(False)\n",
    "        ax.yaxis.grid(True)\n",
    "\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    \n",
    "make_strip_plot(scores,\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "X = np.arange(0, 32)\n",
    "Y = np.arange(0, 32)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = gauss\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_zlim(0, 1)\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
