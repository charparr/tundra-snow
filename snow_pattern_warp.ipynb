{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from collections import defaultdict\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import six\n",
    "%matplotlib qt\n",
    "\n",
    "# View a DataFrame in browser\n",
    "import webbrowser\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# Analysis Libraries\n",
    "import scipy\n",
    "import cv2\n",
    "from scipy import signal\n",
    "from scipy.spatial import *\n",
    "from scipy.ndimage import *\n",
    "from skimage.transform import *\n",
    "from skimage.morphology import *\n",
    "from skimage.util import *\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_mse as mse\n",
    "from skimage.transform import AffineTransform\n",
    "from skimage.transform import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Similarity Test Functions ###\n",
    "\n",
    "def procrustes_analysis(data):\n",
    "    for d in data:\n",
    "        mtx1, mtx2, disparity = procrustes(data[0], d)\n",
    "        # disparity is the sum of the square errors\n",
    "        # mtx2 is the optimal matrix transformation\n",
    "        disp_vals.append(disparity.round(3))\n",
    "\n",
    "def make_quadrants(data):\n",
    "    \n",
    "    q = data[0].shape[0] / 2\n",
    "    for d in data:\n",
    "        tl, tr, ll, lr = d[:q, :q], d[q:, :q], d[:q, q:], d[q:, q:]\n",
    "        top_lefts.append(tl)\n",
    "        top_rights.append(tr)\n",
    "        low_lefts.append(ll)\n",
    "        low_rights.append(tr)\n",
    "        \n",
    "def structural_sim(data):\n",
    "    \n",
    "    for d in data:\n",
    "        ssim_vals.append( ssim ( data[0], d ).round( 2 ))\n",
    "        \n",
    "        ssim_maps.append( ssim ( data[0], d, full  = True )[1] )\n",
    "        \n",
    "def reg_mse(data):\n",
    "    for d in data:\n",
    "        mse_vals.append(( mse ( data[0], d )).round(2))\n",
    "        mse_maps.append((data[0] - d) ** 2)\n",
    "\n",
    "        \n",
    "def imse( data ):\n",
    "    \n",
    "    for d in data:\n",
    "\n",
    "        unique_vals_and_counts = np.round( np.unique( data[0], return_counts = True ), 1 )\n",
    "        vals = np.array( unique_vals_and_counts[0], dtype = 'float32' )\n",
    "        counts = np.array( unique_vals_and_counts[1], dtype = 'float32' )\n",
    "        num_pixels = data[0].size\n",
    "\n",
    "        shannons = np.round( np.divide( counts, num_pixels ), 6 )\n",
    "        info_vals = np.round( np.log(1/shannons), 2)\n",
    "\n",
    "        unique_info_vals = zip(vals,info_vals)\n",
    "        trans_dct = {}\n",
    "\n",
    "        for v in unique_info_vals:\n",
    "            trans_dct[v[0]] = v[1]\n",
    "\n",
    "        infomap = np.copy( data[0] )\n",
    "        for k, v in trans_dct.iteritems(): infomap[data[0] == k] = v\n",
    "\n",
    "        imse_map = (( infomap * data[0] ) - ( infomap * d )) ** 2\n",
    "        imse_maps.append(imse_map)\n",
    "        \n",
    "        err = np.sum( imse_map )\n",
    "        err /= float(data[0].shape[0] * data[0].shape[1])\n",
    "\n",
    "        imse_vals.append( np.round(err, 2 ))\n",
    "\n",
    "# Complex Wavelet SSIM\n",
    "\n",
    "def cw_ssim_value(data, width):\n",
    "        \"\"\"Compute the complex wavelet SSIM (CW-SSIM) value from the reference\n",
    "        image to the target image.\n",
    "        Args:\n",
    "          target (str or PIL.Image): Input image to compare the reference image\n",
    "          to. This may be a PIL Image object or, to save time, an SSIMImage\n",
    "          object (e.g. the img member of another SSIM object).\n",
    "          width: width for the wavelet convolution (default: 30)\n",
    "        Returns:\n",
    "          Computed CW-SSIM float value.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a width for the wavelet convolution\n",
    "        widths = np.arange(1, width+1)\n",
    "\n",
    "        for d in data:\n",
    "        \n",
    "            # Use the image data as arrays\n",
    "            sig1 = np.asarray(data[0].ravel())\n",
    "            sig2 = np.asarray(d.ravel())\n",
    "\n",
    "            # Convolution\n",
    "            cwtmatr1 = signal.cwt(sig1, signal.ricker, widths)\n",
    "            cwtmatr2 = signal.cwt(sig2, signal.ricker, widths)\n",
    "\n",
    "            # Compute the first term\n",
    "            c1c2 = np.multiply(abs(cwtmatr1), abs(cwtmatr2))\n",
    "            c1_2 = np.square(abs(cwtmatr1))\n",
    "            c2_2 = np.square(abs(cwtmatr2))\n",
    "            num_ssim_1 = 2 * np.sum(c1c2, axis=0) + 0.01\n",
    "            den_ssim_1 = np.sum(c1_2, axis=0) + np.sum(c2_2, axis=0) + 0.01\n",
    "\n",
    "            # Compute the second term\n",
    "            c1c2_conj = np.multiply(cwtmatr1, np.conjugate(cwtmatr2))\n",
    "            num_ssim_2 = 2 * np.abs(np.sum(c1c2_conj, axis=0)) + 0.01\n",
    "            den_ssim_2 = 2 * np.sum(np.abs(c1c2_conj), axis=0) + 0.01\n",
    "\n",
    "            # Construct the result\n",
    "            ssim_map = (num_ssim_1 / den_ssim_1) * (num_ssim_2 / den_ssim_2)\n",
    "            ssim_map = ssim_map.reshape(512,512)\n",
    "            cw_ssim_maps.append(ssim_map)\n",
    "\n",
    "            # Average the per pixel results\n",
    "            index = round( np.average(ssim_map), 2) \n",
    "            cw_ssim_vals.append(index)\n",
    "        \n",
    "def np_hist_to_cv(np_histogram_output):\n",
    "    counts, bin_edges = np_histogram_output\n",
    "    return counts.ravel().astype('float32')\n",
    "\n",
    "### Plotting Functions ###\n",
    "\n",
    "# Function to display DataFrame in new browser tab.\n",
    "\n",
    "def df_window(df):\n",
    "    with NamedTemporaryFile(delete=False, suffix='.html') as f:\n",
    "        df.to_html(f)\n",
    "    webbrowser.open(f.name)\n",
    "    \n",
    "def plot_snow(names, data):\n",
    "    \n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    fig.suptitle('Fidelity Tests of Snow Patterns [m]', color = 'white')\n",
    "    for p, dat, ax in zip( names, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'viridis', interpolation = 'nearest', vmin = 0, vmax = 2)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p,fontsize = 8, color = 'white')\n",
    "    \n",
    "    # if # subplots is prime\n",
    "    \n",
    "    fig.delaxes(axes[-1,-1])\n",
    "    fig.delaxes(axes[-1,-2])\n",
    "    fig.delaxes(axes[-1,-3])\n",
    "\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ( [0,1,2] ) )\n",
    "    cax.tick_params(labelsize = 8, colors = 'white')\n",
    "    \n",
    "    \n",
    "def plot_tests(names, test_vals, test_name, data, rows, cols, cmin, cmax):\n",
    "    \n",
    "    fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "    fig.suptitle( test_name + 'Fidelity Test of Snow Patterns' )\n",
    "    \n",
    "    for p, v, dat, ax in zip( names, test_vals, data, axes.flat ):\n",
    "        # The vmin and vmax arguments specify the color limits\n",
    "        im = ax.imshow(dat, cmap = 'viridis', interpolation = 'nearest', vmin = cmin, vmax = cmax)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(p + \" \" + test_name + str(v), fontsize = 6, color = 'white' )\n",
    "    \n",
    "    # if # subplots is strange\n",
    "    if len(names) != rows*cols:\n",
    "        diff = -1*( rows*cols - len(names))\n",
    "        i = -1\n",
    "        while i >= diff:\n",
    "            fig.delaxes(axes[-1,i])\n",
    "            i = i-1\n",
    "    \n",
    "    # Make an axis for the colorbar on the bottom\n",
    "    \n",
    "    cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "    fig.colorbar( im, cax=cax, ticks = ( [cmin, cmax] ) )\n",
    "    cax.tick_params(labelsize = 6, colors = 'white')\n",
    "    \n",
    "def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,\n",
    "                     header_color='#236192', row_colors=['#C7C9C7', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText = data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "    \n",
    "    for k, cell in six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        \n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='#FFCD00')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Snow\n",
    "\n",
    "src1 = rasterio.open( '/home/cparr/Snow_Patterns/snow_data/happy_valley/raster/snow_on/hv_snow_watertrack_square2012.tif' )\n",
    "snow_test = src1.read(1)\n",
    "snow_test = snow_test.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Snow Data Test\n",
    "'''\n",
    "\n",
    "snow_data = []\n",
    "\n",
    "# Initialize lists for metrics.\n",
    "\n",
    "mse_vals = []\n",
    "ssim_vals = []\n",
    "disp_vals = []\n",
    "\n",
    "top_lefts = []\n",
    "top_rights = []\n",
    "low_lefts = []\n",
    "low_rights = []\n",
    "\n",
    "imse_vals = []\n",
    "imse_maps = []\n",
    "\n",
    "mse_maps = []\n",
    "ssim_maps = []\n",
    "mse_maps = []\n",
    "\n",
    "cw_ssim_vals = []\n",
    "cw_ssim_maps = []\n",
    "\n",
    "\n",
    "# Create the test snows.\n",
    "def warp_snow(snow):\n",
    "    \n",
    "    snow_data.append(snow)\n",
    "    \n",
    "    rows, cols = snow.shape\n",
    "    mu = snow.mean()\n",
    "    sigma = snow.std()\n",
    "\n",
    "    # 90 degree rotation\n",
    "    rotate90 = np.rot90(snow)\n",
    "    snow_data.append(rotate90)\n",
    "    \n",
    "    #45 degree rotation\n",
    "    oblique = rotate(snow, 45)\n",
    "    b = oblique == 0\n",
    "    oblique[b] = np.random.normal(mu, sigma, size=b.sum())\n",
    "    snow_data.append(oblique)\n",
    "    \n",
    "    # morphological dilation and erosion\n",
    "\n",
    "    selem = square(7)\n",
    "    morph_dilation = dilation(snow, selem)\n",
    "    morph_erosion = erosion(snow, selem)\n",
    "    snow_data.append(morph_dilation)\n",
    "    snow_data.append(morph_erosion)\n",
    "    \n",
    "    # flip up and down, basically a phase shift\n",
    "    inverse = np.flipud(snow)\n",
    "    snow_data.append(inverse)\n",
    "    \n",
    "    # a shift or translation\n",
    "    shift_M = np.float32([[1,0,1],[0,1,0]])\n",
    "    shifted = cv2.warpAffine(snow,shift_M,(cols,rows))\n",
    "    snow_data.append(shifted)\n",
    "    \n",
    "    # randomly shuffle rows of array, create a random frequency\n",
    "    permutation = np.random.permutation(snow)\n",
    "    snow_data.append(permutation)\n",
    "    \n",
    "    # Random between bounds\n",
    "    random_abs1 = np.random.uniform(snow.min(), snow.max(), [rows, cols])\n",
    "    snow_data.append(random_abs1)\n",
    "    \n",
    "    # Gaussian noise\n",
    "    mu = snow.mean()\n",
    "    sigma = snow.std()\n",
    "    gauss_abs1 = np.random.normal(mu, sigma, (rows, cols))\n",
    "    snow_data.append(gauss_abs1)\n",
    "    \n",
    "    # Random Affine Transformation\n",
    "    \n",
    "    c = np.round(np.random.rand( 3,2 ), 2)\n",
    "    m = np.append( c, ( 0,0,1 ) )\n",
    "    m = m.reshape( 3,3 )\n",
    "    aff_t = AffineTransform( matrix = m )\n",
    "    random_aff_warp = warp( snow, aff_t )\n",
    "    b = random_aff_warp == 0\n",
    "    random_aff_warp[b] = np.random.normal(mu, sigma, size=b.sum())\n",
    "    snow_data.append(random_aff_warp)\n",
    "    \n",
    "    # Additive Gaussian Noise\n",
    "    noise = random_noise( snow, mode = 'gaussian' )\n",
    "    snow_data.append( noise )\n",
    "    \n",
    "    # More Additive Gaussian Noise\n",
    "    more_noise = random_noise(random_noise(random_noise(random_noise( noise, mode = 'gaussian' ))))\n",
    "    snow_data.append( more_noise )\n",
    "    \n",
    "# Plot Titles and dictionary keys\n",
    "snow_names = ['Reference', 'Rotate 90', 'Rotate 45', 'Dilation',\n",
    "                 'Erosion', 'Y - Reflection', 'X Shift', 'Row Shuffle', 'Random', 'Gauss',\n",
    "                 'Random Affine', 'Add Gaussian Noise','More Noise']\n",
    "\n",
    "# Call It.\n",
    "warp_snow( snow_test )\n",
    "\n",
    "# Call Metrics on list of test snows\n",
    "\n",
    "structural_sim( snow_data )\n",
    "reg_mse( snow_data )\n",
    "procrustes_analysis( snow_data )\n",
    "make_quadrants( snow_data )\n",
    "\n",
    "imse(snow_data)\n",
    "\n",
    "cw_ssim_value(snow_data, 30)\n",
    "\n",
    "# Zip names, data, metrics, quadrants into a mega list!\n",
    "# Generally this is indavisable because it relies on indexing...in the next cell we will make a dictionary.\n",
    "snow_zip = zip(snow_names,snow_data, mse_vals, ssim_vals, disp_vals, top_lefts, top_rights, low_lefts, low_rights, \n",
    "               imse_vals, imse_maps, mse_maps, ssim_maps, cw_ssim_vals, cw_ssim_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snow_dict = defaultdict(dict)\n",
    "\n",
    "'''\n",
    "# Making a look up dictionary from all the patterns and their comparison scores.\n",
    "# zipped list [i][0] is namne, 1 is full array, 2 is mse val, 3 is SSIM, 4 is PD,\n",
    "# 5 through 8 are quadrants, 9 is IMSE, 10 is IMSE Map, 11 is MSE Map, 12 SSIM Map, 13 CWSSIM, 14 CWSSIM Map\n",
    "'''\n",
    "\n",
    "def to_dict_w_hists( data_dict, keys, data_zip ):\n",
    "\n",
    "    i = 0\n",
    "    while i < len(keys):\n",
    "\n",
    "        data_dict[keys[i]]['name'] = data_zip[i][0]\n",
    "\n",
    "        data_dict[keys[i]]['arrays'] = {}\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['full'] = {}\n",
    "        data_dict[keys[i]]['arrays']['full']['array'] = data_zip[i][1]\n",
    "        data_dict[keys[i]]['arrays']['full']['numpy hist'] = np.histogram( data_zip[i][1] )\n",
    "        data_dict[keys[i]]['arrays']['full']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][1] ) )\n",
    "        \n",
    "        data_dict[keys[i]]['MSE'] = round(data_zip[i][2], 2)\n",
    "        data_dict[keys[i]]['SSIM'] = round(data_zip[i][3], 2)\n",
    "        data_dict[keys[i]]['Procrustres Disparity'] = round(data_zip[i][4], 2)\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['top left'] = {}\n",
    "        data_dict[keys[i]]['arrays']['top left']['array'] = data_zip[i][5]\n",
    "        data_dict[keys[i]]['arrays']['top left']['numpy hist'] = np.histogram( data_zip[i][5] )\n",
    "        data_dict[keys[i]]['arrays']['top left']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][5] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['top right'] = {}\n",
    "        data_dict[keys[i]]['arrays']['top right']['array'] = data_zip[i][6]\n",
    "        data_dict[keys[i]]['arrays']['top right']['numpy hist'] = np.histogram( data_zip[i][6] )\n",
    "        data_dict[keys[i]]['arrays']['top right']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][6] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['low left'] = {}\n",
    "        data_dict[keys[i]]['arrays']['low left']['array'] = data_zip[i][7]\n",
    "        data_dict[keys[i]]['arrays']['low left']['numpy hist'] = np.histogram( data_zip[i][7] )\n",
    "        data_dict[keys[i]]['arrays']['low left']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][7] ) )\n",
    "\n",
    "        data_dict[keys[i]]['arrays']['low right'] = {}\n",
    "        data_dict[keys[i]]['arrays']['low right']['array'] = data_zip[i][8]\n",
    "        data_dict[keys[i]]['arrays']['low right']['numpy hist'] = np.histogram( data_zip[i][8] )\n",
    "        data_dict[keys[i]]['arrays']['low right']['cv2 hist'] = np_hist_to_cv( np.histogram( data_zip[i][8] ) )    \n",
    "\n",
    "        data_dict[keys[i]]['IMSE'] = round(data_zip[i][9], 2)\n",
    "        data_dict[keys[i]]['IMSE Map'] = data_zip[i][10]\n",
    "        data_dict[keys[i]]['MSE Map'] = data_zip[i][11]\n",
    "        data_dict[keys[i]]['SSIM Map'] = data_zip[i][12]\n",
    "        data_dict[keys[i]]['CW SSIM'] = data_zip[i][13]\n",
    "        data_dict[keys[i]]['CW SSIM Map'] = data_zip[i][14]\n",
    "\n",
    "        # Histogram Comparisons\n",
    "\n",
    "        # Bhattacharyya\n",
    "        data_dict[keys[i]]['Bhattacharyya Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)   \n",
    "\n",
    "        data_dict[keys[i]]['Bhattacharyya LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_BHATTACHARYYA), 2)\n",
    "\n",
    "        # Chi Square\n",
    "        data_dict[keys[i]]['Chi Square Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Chi Square LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CHISQR), 2)\n",
    "\n",
    "        # Correlation\n",
    "        data_dict[keys[i]]['Correlation Full'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['full']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['full']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation UL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation UR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['top right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['top right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation LL'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low left']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low left']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        data_dict[keys[i]]['Correlation LR'] = round(cv2.compareHist(\n",
    "                data_dict[keys[i]]['arrays']['low right']['cv2 hist'],\n",
    "                data_dict[keys[0]]['arrays']['low right']['cv2 hist'],\n",
    "                cv2.cv.CV_COMP_CORREL), 2)\n",
    "\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_dict_w_hists( snow_dict, snow_names, snow_zip )\n",
    "snow_df = pd.DataFrame.from_dict(snow_dict)\n",
    "snow_df = snow_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram Scores\n",
    "\n",
    "hist_scores = snow_df.loc[:,['name', 'Bhattacharyya UL','Bhattacharyya UR','Bhattacharyya LL',\n",
    "'Bhattacharyya LR', 'Bhattacharyya Full','Correlation UL','Correlation UR','Correlation LL',\n",
    "'Correlation LR', 'Correlation Full','Chi Square UL','Chi Square UR','Chi Square LL',\n",
    "'Chi Square LR', 'Chi Square Full']]\n",
    "\n",
    "hist_scores['Mean Bhattacharyya'] = np.round(hist_scores[['Bhattacharyya UL','Bhattacharyya UR',\n",
    "                                            'Bhattacharyya LL', 'Bhattacharyya LR']].mean(axis = 1),2)\n",
    "\n",
    "hist_scores['Mean Correlation'] = np.round(hist_scores[['Correlation UL','Correlation UR',\n",
    "                                            'Correlation LL', 'Correlation LR']].mean(axis = 1),2)\n",
    "\n",
    "hist_scores['Mean Chi Square'] = np.round(hist_scores[['Chi Square UL','Chi Square UR',\n",
    "                                            'Chi Square LL', 'Chi Square LR']].mean(axis = 1),2)\n",
    "\n",
    "hist_scores = hist_scores[['Mean Bhattacharyya', 'Mean Chi Square','Mean Correlation']]\n",
    "\n",
    "\n",
    "hist_scores = hist_scores.sort_values('Mean Bhattacharyya')\n",
    "\n",
    "#df_window(hist_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Snow Scores and Ranks\n",
    "\n",
    "snow_scores = snow_df.copy()\n",
    "snow_scores['Pattern'] = snow_df['name']\n",
    "snow_scores = snow_scores[['Pattern', 'MSE', 'SSIM', 'IMSE', 'Procrustres Disparity', 'CW SSIM']]\n",
    "snow_scores = snow_scores.sort_values( 'CW SSIM', ascending = False )\n",
    "\n",
    "ranks = snow_scores.copy()\n",
    "ranks['Pattern'] = snow_df['name']\n",
    "ranks['MSE Rank'] = np.round(snow_scores['MSE'].rank(ascending=True))\n",
    "ranks['SSIM Rank'] = snow_scores['SSIM'].rank(ascending=False)\n",
    "ranks['IMSE Rank'] = np.round(snow_scores['IMSE'].rank(ascending=True))\n",
    "ranks['CW-SSIM Rank'] = snow_scores['CW SSIM'].rank(ascending=False)\n",
    "ranks['Disparity Rank'] = snow_scores['Procrustres Disparity'].rank()\n",
    "ranks['Bhattacharyya Rank'] = hist_scores['Mean Bhattacharyya'].rank(ascending=True)\n",
    "ranks['Chi Square Rank'] = hist_scores['Mean Chi Square'].rank(ascending=True)\n",
    "ranks['Correlation Rank'] = hist_scores['Mean Correlation'].rank(ascending=False)\n",
    "del ranks['MSE']\n",
    "del ranks['IMSE']\n",
    "del ranks['SSIM']\n",
    "del ranks['CW SSIM']\n",
    "del ranks ['Procrustres Disparity']\n",
    "ranks = ranks.sort_values('CW-SSIM Rank')\n",
    "\n",
    "#df_window(snow_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_mpl_table(ranks)\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/snow_test_ranks.png', bbox_inches = 'tight', dpi = 300)\n",
    "plt.close()\n",
    "\n",
    "render_mpl_table(snow_scores)\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/snow_test_scores.png', bbox_inches = 'tight', dpi = 300)\n",
    "plt.close()\n",
    "\n",
    "plot_snow( snow_names, snow_data )\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_snow_warps.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "plt.close()\n",
    "# names, test_vals, test_name, data, rows, cols, cmin, cmax\n",
    "\n",
    "plot_tests( snow_names, imse_vals, \" IMSE: \", imse_maps, 4, 4, 0, 1 )\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_imse_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "plt.close()\n",
    "\n",
    "plot_tests( snow_names, mse_vals, \" MSE: \", mse_maps, 4, 4, 0, 1 )\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_mse_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "plt.close()\n",
    "\n",
    "plot_tests( snow_names, ssim_vals, \" SSIM: \", ssim_maps, 4, 4, -1, 1 )\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_ssim_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "plt.close()\n",
    "\n",
    "plot_tests( snow_names, cw_ssim_vals, \" CW SSIM: \", cw_ssim_maps, 4, 4, -1, 1 )\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_cw_ssim_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots( nrows = 4, ncols = 4 )\n",
    "fig.suptitle('Fidelity Tests of Snow Depth Patterns [m]', color = 'white')\n",
    "for p, dat, ax in zip( snow_names, snow_data, axes.flat ):\n",
    "    \n",
    "    contours = measure.find_contours(dat, 0.8)\n",
    "\n",
    "    # The vmin and vmax arguments specify the color limits\n",
    "    im = ax.imshow(dat, cmap = 'gray', interpolation = 'nearest', vmin = 0, vmax = 2)\n",
    "    \n",
    "    for n, contour in enumerate(contours):\n",
    "        if contour.size >= 150:\n",
    "            ax.plot(contour[:, 1], contour[:, 0], linewidth=0.5)\n",
    "\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(p,fontsize = 8, color = 'white')\n",
    "    ax.axis('image')\n",
    "\n",
    "\n",
    "# if # subplots is prime\n",
    "\n",
    "fig.delaxes(axes[-1,-1])\n",
    "fig.delaxes(axes[-1,-2])\n",
    "fig.delaxes(axes[-1,-3])\n",
    "\n",
    "\n",
    "# Make an axis for the colorbar on the bottom\n",
    "\n",
    "cax = fig.add_axes( [0.05, 0.2, 0.04, 0.6] )\n",
    "fig.colorbar( im, cax=cax, ticks = ( [0,1,2] ) )\n",
    "cax.tick_params(labelsize = 8, colors = 'white')\n",
    "\n",
    "plt.savefig('/home/cparr/Snow_Patterns/figures/hv_snow_test/hv_contour_map.png', bbox_inches = 'tight', dpi = 300, facecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
